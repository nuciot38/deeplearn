# 论文

- Going Deeper with Convolutions
- Network in Networks



![img](https://images2015.cnblogs.com/blog/822124/201609/822124-20160902163822558-1475761330.png)

## 辅助器具体细节

- 均值pooling层滤波器大小为5x5，步长为3，(4a)的输出为4x4x512，(4d)的输出为4x4x528； 
- 1x1的卷积有用于降维的128个滤波器和修正线性激活；
- 全连接层有1024个单元和修正线性激活；
- dropout层的dropped的输出比率为70%； 
- 线性层将softmax损失作为分类器（和主分类器一样预测1000个类，但在inference时移除）。



## 测试技巧

- 训练了7个网络，初始化和权重都相同，只是采样方法和随机输入图像不同； 
- 将图像的短边分别缩放成256、288、320、352这样4种尺度。取图像的左中右块（或上中下块）。每块取四个角和中间的224x224的裁剪，和将这个块缩放到224x224，以及它们的镜像。这样每个图像有4x3x6x2=144个，但可能实际中不需要这么多；
- softmax概率在多个裁剪和在所有分类器上取平均来获得最后的预测，简单的平均结果最好。 



## 核心思想

### 1x1卷积

- 作用1：在相同尺寸的感受野中叠加更多的卷积，能提取到更丰富的特征。
- 作用2：使用1x1卷积进行降维，降低了计算复杂度。

### 多个尺寸上进行卷积再聚合

- 解释1：在直观感觉上在多个尺度上同时进行卷积，能提取到不同尺度的特征。特征更为丰富也意味着最后分类判断时更加准确。
- 解释2：利用稀疏矩阵分解成密集矩阵计算的原理来加快收敛速度。
- 解释3：Hebbin赫布原理



GoogLeNet网络结构明细表解析如下：

> **0、输入**
>  原始输入图像为224x224x3，且都进行了零均值化的预处理操作（图像每个像素减去均值）。
>  **1、第一层（卷积层）**
>  使用7x7的卷积核（滑动步长2，padding为3），64通道，输出为112x112x64，卷积后进行ReLU操作
>  经过3x3的max pooling（步长为2），输出为((112 - 3+1)/2)+1=56，即56x56x64，再进行ReLU操作
>  **2、第二层（卷积层）**
>  使用3x3的卷积核（滑动步长为1，padding为1），192通道，输出为56x56x192，卷积后进行ReLU操作
>  经过3x3的max pooling（步长为2），输出为((56 - 3+1)/2)+1=28，即28x28x192，再进行ReLU操作
>  **3a、第三层（Inception 3a层）**
>  分为四个分支，采用不同尺度的卷积核来进行处理
>  （1）64个1x1的卷积核，然后RuLU，输出28x28x64
>  （2）96个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x96，然后进行ReLU计算，再进行128个3x3的卷积（padding为1），输出28x28x128
>  （3）16个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x16，进行ReLU计算后，再进行32个5x5的卷积（padding为2），输出28x28x32
>  （4）pool层，使用3x3的核（padding为1），输出28x28x192，然后进行32个1x1的卷积，输出28x28x32。
>  将四个结果进行连接，对这四部分输出结果的第三维并联，即64+128+32+32=256，最终输出28x28x256
>  **3b、第三层（Inception 3b层）**
>  （1）128个1x1的卷积核，然后RuLU，输出28x28x128
>  （2）128个1x1的卷积核，作为3x3卷积核之前的降维，变成28x28x128，进行ReLU，再进行192个3x3的卷积（padding为1），输出28x28x192
>  （3）32个1x1的卷积核，作为5x5卷积核之前的降维，变成28x28x32，进行ReLU计算后，再进行96个5x5的卷积（padding为2），输出28x28x96
>  （4）pool层，使用3x3的核（padding为1），输出28x28x256，然后进行64个1x1的卷积，输出28x28x64。
>  将四个结果进行连接，对这四部分输出结果的第三维并联，即128+192+96+64=480，最终输出输出为28x28x480
>
> 第四层（4a,4b,4c,4d,4e）、第五层（5a,5b）……，与3a、3b类似，在此就不再重复。从GoogLeNet的实验结果来看，效果很明显，差错率比MSRA、VGG等模型都要低，