# 论文

- Very deep convolutional networks for LARGE-SCALE IMAGE RECOGNITION





![img](https://gss2.bdstatic.com/-fo3dSag_xI4khGkpoWK1HF6hhy/baike/c0%3Dbaike116%2C5%2C5%2C116%2C38/sign=67b4d6e8ca5c10383073c690d378f876/8c1001e93901213f36ea982e58e736d12e2e9563.jpg)



## 架构

​	在训练期间，我们的ConvNet的输入是固定大小的224 * 224的RGB图像。我们做的唯一的预处理是从每个像素值上减去在训练集上计算的平均RGB值。图像通过一堆卷积层（conv），其中我们使用具有非常小的接收野的滤波器：3*3（这是捕获左/右，上/下，中心概念的最小尺寸）。在其中一个配置中，我们还使用了1 *  1的卷积过滤器，这可以看作是输入通道的线性变换（之后接一个非线性变换）。卷积步长固定为1个像素；卷积层的输入的空间填充是使得在卷积之后保留空间分辨率，如，对于一个3 * 3的卷积层来说填充是1个像素。空间池化是由5个最大池化层执行的，基在一些卷积层后面（不是所有的卷积层之后都跟着最大池化层）。最大池化是在2*2的像素窗口上执行的，步长为2。
​	一堆卷积层（在不同的架构中具有不同的深度）之后是三个全连接层（FC）：前两个每一个都有4096个通道，第三个执行1000类的ILSVRC分类，因此包含1000个通道（每个类一个通道）。最后一层是soft-max层。全连接层的配置在所有网络中都是相同的。
所有的隐藏层都配有修正的非线性单元（ReLU）。注意到我们的网络只有一个包含有局部响应正则化（LRN）：会在第4节中展示，这种正则化不会改善在ILSVRC数据集中的性能，但会导致内存消耗和计算时间增加。在适用的情况下，LRN层的参数是（Krizhevsky et al., 2012）等人的参数。



## 与AlexNet的对比

### 相同点

1. 最后三层FC层(Fully Connected全连接层）结构相同。
2. 都分成五层（组）。
3. 每层和每层之间用pooling层分开。

### 不同点

1. AlexNet每层仅仅含有一个Convolution层，filter的大小7x7（很大）；而VGG每层含有多个(2~4)个Convolution层，filter的大小是3x3（最小）。很明显，VGG是在模仿Alex的结构，然而它通过降低filter的大小，增加层数来达到同样的效果。
2. AlexNet的Channel明显小于VGG。猜测VGG的之所以能够达到更高的精准性，源自于更多的Channel数。而由于filter size的减小，channel可以大幅度增加，更多的信息可以被提取。

